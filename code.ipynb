{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc4cf0c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-24T01:56:45.911131Z",
     "iopub.status.busy": "2024-07-24T01:56:45.910504Z",
     "iopub.status.idle": "2024-07-24T01:57:21.507036Z",
     "shell.execute_reply": "2024-07-24T01:57:21.505864Z"
    },
    "papermill": {
     "duration": 35.605358,
     "end_time": "2024-07-24T01:57:21.509631",
     "exception": false,
     "start_time": "2024-07-24T01:56:45.904273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/whoosh-wheel-2-7-4/Whoosh-2.7.4-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.10/site-packages (from Whoosh==2.7.4) (1.5.2)\r\n",
      "Installing collected packages: Whoosh\r\n",
      "Successfully installed Whoosh-2.7.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/whoosh-wheel-2-7-4/Whoosh-2.7.4-py2.py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08894c1",
   "metadata": {
    "papermill": {
     "duration": 0.004489,
     "end_time": "2024-07-24T01:57:21.519354",
     "exception": false,
     "start_time": "2024-07-24T01:57:21.514865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Based on https://www.kaggle.com/code/tubotubo/uspto-simulated-annealing-baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a64c15",
   "metadata": {
    "papermill": {
     "duration": 0.004458,
     "end_time": "2024-07-24T01:57:21.528418",
     "exception": false,
     "start_time": "2024-07-24T01:57:21.523960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Test Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c123a84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T01:57:21.539247Z",
     "iopub.status.busy": "2024-07-24T01:57:21.538947Z",
     "iopub.status.idle": "2024-07-24T01:58:22.361330Z",
     "shell.execute_reply": "2024-07-24T01:58:22.360364Z"
    },
    "papermill": {
     "duration": 60.83073,
     "end_time": "2024-07-24T01:58:22.363748",
     "exception": false,
     "start_time": "2024-07-24T01:57:21.533018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/whoosh-wheel-2-7-4/Whoosh-2.7.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.10/site-packages (from Whoosh==2.7.4) (1.5.2)\n",
      "Whoosh is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:03<00:00, 93.22it/s]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "import whoosh_utils\n",
    "\n",
    "comp_data_dir = Path(\"/kaggle/input/uspto-explainable-ai\")\n",
    "\n",
    "# Read patent since 1975\n",
    "meta = pl.scan_parquet(comp_data_dir / \"patent_metadata.parquet\")\n",
    "meta = (\n",
    "    meta.with_columns(\n",
    "        pl.col(\"publication_date\").dt.year().alias(\"year\"),\n",
    "        pl.col(\"publication_date\").dt.month().alias(\"month\"),\n",
    "    )\n",
    "     #.filter(pl.col(\"publication_date\") >= pl.date(1975, 1, 1))\n",
    "    .rename({\"cpc_codes\": \"cpc\"})\n",
    "    .collect()\n",
    ")\n",
    "test_nn = pl.scan_csv(comp_data_dir / \"test.csv\")\n",
    "# test_nn = pl.read_csv(comp_data_dir / \"nearest_neighbors.csv\").sample(2500).lazy()\n",
    "\n",
    "# Filtering only the patent meta-information that appears in the test\n",
    "all_pub = test_nn.melt().collect().get_column(\"value\").unique()\n",
    "meta = meta.filter(pl.col(\"publication_number\").is_in(all_pub))\n",
    "\n",
    "# Join meta information\n",
    "patents = []\n",
    "n_unique = meta.select([\"year\", \"month\"]).n_unique()\n",
    "for (year, month), _ in tqdm(meta.group_by([\"year\", \"month\"]), total=n_unique):\n",
    "    patent_path = comp_data_dir / f\"patent_data/{year}_{month}.parquet\"\n",
    "    patent = pl.scan_parquet(patent_path).select(pl.exclude([\"claims\", \"description\"]))\n",
    "    patents.append(patent)\n",
    "patent: pl.LazyFrame = pl.concat(patents)\n",
    "patent = patent.with_columns(\n",
    "    pl.lit(\"\").alias(\"claims\"),\n",
    "    pl.lit(\"\").alias(\"description\"),\n",
    ")\n",
    "meta_with_text = (\n",
    "    meta.lazy().join(patent, on=\"publication_number\", how=\"left\").collect(streaming=True)\n",
    ")\n",
    "meta_with_text.write_parquet(\"meta_with_text.parquet\")\n",
    "\n",
    "# create index\n",
    "documents = meta_with_text.to_dicts()\n",
    "Path(\"test_index\").mkdir(parents=True, exist_ok=True)\n",
    "whoosh_utils.create_index(\"test_index\", documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f10d82",
   "metadata": {
    "papermill": {
     "duration": 0.004982,
     "end_time": "2024-07-24T01:58:22.374222",
     "exception": false,
     "start_time": "2024-07-24T01:58:22.369240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Annealing\n",
    "\n",
    "Optimize the query using the annealing method.\n",
    "\n",
    "For simplicity, we will create a query using only “OR”.\n",
    "This means that we will create a query “word1 OR word2 OR word3 OR ...”.\n",
    "\n",
    "We will use an annealing method to determine which words to use.\n",
    "The specific steps are as follows\n",
    "\n",
    "1. select topk words with high TFIDF values as candidates\n",
    "2. select the word with the maximum AP@50 using the annealing method\n",
    "3. Combine the selected words with “OR” to form a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5589da98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T01:58:22.386079Z",
     "iopub.status.busy": "2024-07-24T01:58:22.385777Z",
     "iopub.status.idle": "2024-07-24T01:58:22.418044Z",
     "shell.execute_reply": "2024-07-24T01:58:22.417223Z"
    },
    "papermill": {
     "duration": 0.040653,
     "end_time": "2024-07-24T01:58:22.419884",
     "exception": false,
     "start_time": "2024-07-24T01:58:22.379231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/perrygeo/simanneal/blob/master/simanneal/anneal.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "import abc\n",
    "import copy\n",
    "import datetime\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import signal\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "def round_figures(x, n):\n",
    "    \"\"\"Returns x rounded to n significant figures.\"\"\"\n",
    "    return round(x, int(n - math.ceil(math.log10(abs(x)))))\n",
    "\n",
    "\n",
    "def time_string(seconds):\n",
    "    \"\"\"Returns time in seconds as a string formatted HHHH:MM:SS.\"\"\"\n",
    "    s = int(round(seconds))  # round to nearest second\n",
    "    h, s = divmod(s, 3600)  # get hours and remainder\n",
    "    m, s = divmod(s, 60)  # split remainder into minutes and seconds\n",
    "    return \"%4i:%02i:%02i\" % (h, m, s)\n",
    "\n",
    "\n",
    "class Annealer(object):\n",
    "    \"\"\"Performs simulated annealing by calling functions to calculate\n",
    "    energy and make moves on a state.  The temperature schedule for\n",
    "    annealing may be provided manually or estimated automatically.\n",
    "    \"\"\"\n",
    "\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "\n",
    "    # defaults\n",
    "    Tmax = 25000.0\n",
    "    Tmin = 2.5\n",
    "    steps = 50000\n",
    "    max_time = 8  # seconds\n",
    "    updates = 100\n",
    "    copy_strategy = \"deepcopy\"\n",
    "    user_exit = False\n",
    "    save_state_on_exit = False\n",
    "\n",
    "    # placeholders\n",
    "    best_state = None\n",
    "    best_energy = None\n",
    "    start = None\n",
    "\n",
    "    def __init__(self, initial_state=None, load_state=None):\n",
    "        if initial_state is not None:\n",
    "            self.state = self.copy_state(initial_state)\n",
    "        elif load_state:\n",
    "            self.load_state(load_state)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"No valid values supplied for neither \\\n",
    "            initial_state nor load_state\"\n",
    "            )\n",
    "\n",
    "        signal.signal(signal.SIGINT, self.set_user_exit)\n",
    "\n",
    "    def save_state(self, fname=None):\n",
    "        \"\"\"Saves state to pickle\"\"\"\n",
    "        if not fname:\n",
    "            date = datetime.datetime.now().strftime(\"%Y-%m-%dT%Hh%Mm%Ss\")\n",
    "            fname = date + \"_energy_\" + str(self.energy()) + \".state\"\n",
    "        with open(fname, \"wb\") as fh:\n",
    "            pickle.dump(self.state, fh)\n",
    "\n",
    "    def load_state(self, fname=None):\n",
    "        \"\"\"Loads state from pickle\"\"\"\n",
    "        with open(fname, \"rb\") as fh:\n",
    "            self.state = pickle.load(fh)\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def move(self):\n",
    "        \"\"\"Create a state change\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def energy(self):\n",
    "        \"\"\"Calculate state's energy\"\"\"\n",
    "        pass\n",
    "\n",
    "    def set_user_exit(self, signum, frame):\n",
    "        \"\"\"Raises the user_exit flag, further iterations are stopped\"\"\"\n",
    "        self.user_exit = True\n",
    "\n",
    "    def set_schedule(self, schedule):\n",
    "        \"\"\"Takes the output from `auto` and sets the attributes\"\"\"\n",
    "        self.Tmax = schedule[\"tmax\"]\n",
    "        self.Tmin = schedule[\"tmin\"]\n",
    "        self.steps = int(schedule[\"steps\"])\n",
    "        self.updates = int(schedule[\"updates\"])\n",
    "\n",
    "    def copy_state(self, state):\n",
    "        \"\"\"Returns an exact copy of the provided state\n",
    "        Implemented according to self.copy_strategy, one of\n",
    "\n",
    "        * deepcopy: use copy.deepcopy (slow but reliable)\n",
    "        * slice: use list slices (faster but only works if state is list-like)\n",
    "        * method: use the state's copy() method\n",
    "        \"\"\"\n",
    "        if self.copy_strategy == \"deepcopy\":\n",
    "            return copy.deepcopy(state)\n",
    "        elif self.copy_strategy == \"slice\":\n",
    "            return state[:]\n",
    "        elif self.copy_strategy == \"method\":\n",
    "            return state.copy()\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                \"No implementation found for \" + 'the self.copy_strategy \"%s\"' % self.copy_strategy\n",
    "            )\n",
    "\n",
    "    def update(self, *args, **kwargs):\n",
    "        \"\"\"Wrapper for internal update.\n",
    "\n",
    "        If you override the self.update method,\n",
    "        you can chose to call the self.default_update method\n",
    "        from your own Annealer.\n",
    "        \"\"\"\n",
    "        self.default_update(*args, **kwargs)\n",
    "\n",
    "    def default_update(self, step, T, E, acceptance, improvement):\n",
    "        \"\"\"Default update, outputs to stderr.\n",
    "\n",
    "        Prints the current temperature, energy, acceptance rate,\n",
    "        improvement rate, elapsed time, and remaining time.\n",
    "\n",
    "        The acceptance rate indicates the percentage of moves since the last\n",
    "        update that were accepted by the Metropolis algorithm.  It includes\n",
    "        moves that decreased the energy, moves that left the energy\n",
    "        unchanged, and moves that increased the energy yet were reached by\n",
    "        thermal excitation.\n",
    "\n",
    "        The improvement rate indicates the percentage of moves since the\n",
    "        last update that strictly decreased the energy.  At high\n",
    "        temperatures it will include both moves that improved the overall\n",
    "        state and moves that simply undid previously accepted moves that\n",
    "        increased the energy by thermal excititation.  At low temperatures\n",
    "        it will tend toward zero as the moves that can decrease the energy\n",
    "        are exhausted and moves that would increase the energy are no longer\n",
    "        thermally accessible.\"\"\"\n",
    "\n",
    "        elapsed = time.time() - self.start\n",
    "        if step == 0:\n",
    "            print(\n",
    "                \"\\n Temperature        Energy    Accept   Improve     Elapsed   Remaining\",\n",
    "                file=sys.stderr,\n",
    "            )\n",
    "            print(\n",
    "                \"\\r{Temp:12.5f}  {Energy:12.2f}                      {Elapsed:s}            \".format(\n",
    "                    Temp=T, Energy=E, Elapsed=time_string(elapsed)\n",
    "                ),\n",
    "                file=sys.stderr,\n",
    "                end=\"\",\n",
    "            )\n",
    "            sys.stderr.flush()\n",
    "        else:\n",
    "            remain = (self.steps - step) * (elapsed / step)\n",
    "            print(\n",
    "                \"\\r{Temp:12.5f}  {Energy:12.2f}   {Accept:7.2%}   {Improve:7.2%}  {Elapsed:s}  {Remaining:s}\".format(\n",
    "                    Temp=T,\n",
    "                    Energy=E,\n",
    "                    Accept=acceptance,\n",
    "                    Improve=improvement,\n",
    "                    Elapsed=time_string(elapsed),\n",
    "                    Remaining=time_string(remain),\n",
    "                ),\n",
    "                file=sys.stderr,\n",
    "                end=\"\",\n",
    "            )\n",
    "            sys.stderr.flush()\n",
    "\n",
    "    def anneal(self):\n",
    "        \"\"\"Minimizes the energy of a system by simulated annealing.\n",
    "\n",
    "        Parameters\n",
    "        state : an initial arrangement of the system\n",
    "\n",
    "        Returns\n",
    "        (state, energy): the best state and energy found.\n",
    "        \"\"\"\n",
    "        step = 0\n",
    "        self.start = time.time()\n",
    "\n",
    "        # Precompute factor for exponential cooling from Tmax to Tmin\n",
    "        if self.Tmin <= 0.0:\n",
    "            raise Exception(\n",
    "                'Exponential cooling requires a minimum \"\\\n",
    "                \"temperature greater than zero.'\n",
    "            )\n",
    "        Tfactor = -math.log(self.Tmax / self.Tmin)\n",
    "\n",
    "        # Note initial state\n",
    "        T = self.Tmax\n",
    "        E = self.energy()\n",
    "        prevState = self.copy_state(self.state)\n",
    "        prevEnergy = E\n",
    "        self.best_state = self.copy_state(self.state)\n",
    "        self.best_energy = E\n",
    "        trials = accepts = improves = 0\n",
    "        if self.updates > 0:\n",
    "            updateWavelength = self.steps / self.updates\n",
    "            self.update(step, T, E, None, None)\n",
    "\n",
    "        # Attempt moves to new states\n",
    "        while (\n",
    "            (step < self.steps)\n",
    "            and (not self.user_exit)\n",
    "            and ((time.time() - self.start) <= self.max_time)\n",
    "        ):\n",
    "            step += 1\n",
    "            T = self.Tmax * math.exp(Tfactor * step / self.steps)\n",
    "            dE = self.move()\n",
    "            if dE is None:\n",
    "                E = self.energy()\n",
    "                dE = E - prevEnergy\n",
    "            else:\n",
    "                E += dE\n",
    "            trials += 1\n",
    "            if dE > 0.0 and math.exp(-dE / T) < random.random():\n",
    "                # Restore previous state\n",
    "                self.state = self.copy_state(prevState)\n",
    "                E = prevEnergy\n",
    "            else:\n",
    "                # Accept new state and compare to best state\n",
    "                accepts += 1\n",
    "                if dE < 0.0:\n",
    "                    improves += 1\n",
    "                prevState = self.copy_state(self.state)\n",
    "                prevEnergy = E\n",
    "                if E < self.best_energy:\n",
    "                    self.best_state = self.copy_state(self.state)\n",
    "                    self.best_energy = E\n",
    "            if self.updates > 1:\n",
    "                if (step // updateWavelength) > ((step - 1) // updateWavelength):\n",
    "                    self.update(step, T, E, accepts / trials, improves / trials)\n",
    "                    trials = accepts = improves = 0\n",
    "\n",
    "        self.state = self.copy_state(self.best_state)\n",
    "        if self.save_state_on_exit:\n",
    "            self.save_state()\n",
    "\n",
    "        # Return best state and energy\n",
    "        return self.best_state, self.best_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a27d6e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T01:58:22.431324Z",
     "iopub.status.busy": "2024-07-24T01:58:22.430801Z",
     "iopub.status.idle": "2024-07-24T01:58:53.694148Z",
     "shell.execute_reply": "2024-07-24T01:58:53.693134Z"
    },
    "papermill": {
     "duration": 31.271981,
     "end_time": "2024-07-24T01:58:53.696990",
     "exception": false,
     "start_time": "2024-07-24T01:58:22.425009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/whoosh-wheel-2-7-4/Whoosh-2.7.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.10/site-packages (from Whoosh==2.7.4) (1.5.2)\n",
      "Whoosh is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from typing import Any\n",
    "import whoosh_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f2c5260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T01:58:53.709355Z",
     "iopub.status.busy": "2024-07-24T01:58:53.709065Z",
     "iopub.status.idle": "2024-07-24T01:58:53.724756Z",
     "shell.execute_reply": "2024-07-24T01:58:53.723960Z"
    },
    "papermill": {
     "duration": 0.024028,
     "end_time": "2024-07-24T01:58:53.726617",
     "exception": false,
     "start_time": "2024-07-24T01:58:53.702589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_top_k_columns(X: Any, k: int) -> tuple[Any, NDArray]:\n",
    "    # 行方向の和を計算\n",
    "    row_sums = X.sum(axis=0)\n",
    "    \n",
    "    #valid_indices = np.where(row_sums.A1 >= 0)[0]\n",
    "\n",
    "    # 和が大きい上位k個の列のインデックスを取得\n",
    "    top_k_indices = np.argsort(-row_sums.A1)[:k]\n",
    "    #top_k_indices = np.intersect1d(top_k_indices, valid_indices)\n",
    "    \n",
    "    #top_k_value = row_sums.A1[top_k_indices]\n",
    "    #print(top_k_indices,top_k_value)\n",
    "\n",
    "    # 上位k個の列を選択\n",
    "    X_top = X[:, top_k_indices]\n",
    "\n",
    "    return X_top, top_k_indices\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/competitions/uspto-explainable-ai/discussion/499981#2791642\n",
    "def ap50(preds: list[str], labels: list[str]) -> float:\n",
    "    precisions = list()\n",
    "    n_found = 0\n",
    "    for e, i in enumerate(preds):\n",
    "        if i in labels:\n",
    "            n_found += 1\n",
    "        precisions.append(\n",
    "            n_found / (e + 1)\n",
    "        )  # this is the line that is probably incorrect for competition\n",
    "    return sum(precisions) / 50\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Word:\n",
    "    category: str\n",
    "    content: str\n",
    "\n",
    "    def to_str(self):\n",
    "        return f\"{self.category}:{self.content}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class State:\n",
    "    words: list[Word]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.use = np.random.binomial(1, 0.5, len(self.words))\n",
    "\n",
    "    def to_query(self):\n",
    "        words = [word.to_str() for word, use in zip(self.words, self.use) if use]\n",
    "\n",
    "        return \" OR \".join(words)\n",
    "\n",
    "    def move_1(self):\n",
    "        \"\"\"Change whether word is used or not\"\"\"\n",
    "        idx = np.random.choice(len(self.words))\n",
    "        self.use[idx] = 1 - self.use[idx]\n",
    "        return self\n",
    "\n",
    "\n",
    "class USPTOProblem(Annealer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        qp: Any,\n",
    "        searcher: Any,\n",
    "        target: list[str],\n",
    "        init_state: State,\n",
    "        tmax: int = 30,\n",
    "        tmin: int = 10,\n",
    "        steps: int = 100,\n",
    "        max_time: int = 8,\n",
    "        copy_strategy: str = \"deepcopy\",\n",
    "    ):\n",
    "        super(USPTOProblem, self).__init__(init_state)\n",
    "        self.qp = qp\n",
    "        self.searcher = searcher\n",
    "        self.target = target\n",
    "        self.Tmax = tmax\n",
    "        self.Tmin = tmin\n",
    "        self.steps = steps\n",
    "        self.max_time = max_time\n",
    "        self.copy_strategy = copy_strategy\n",
    "\n",
    "    def move(self):\n",
    "        self.state.move_1()\n",
    "\n",
    "    def energy(self):\n",
    "        query = self.state.to_query()\n",
    "        cand = whoosh_utils.execute_query(query, self.qp, self.searcher)\n",
    "        ap50_score = ap50(cand, self.target)\n",
    "\n",
    "        return -ap50_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a637ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T01:58:53.737980Z",
     "iopub.status.busy": "2024-07-24T01:58:53.737710Z",
     "iopub.status.idle": "2024-07-24T01:58:56.157493Z",
     "shell.execute_reply": "2024-07-24T01:58:56.156484Z"
    },
    "papermill": {
     "duration": 2.427819,
     "end_time": "2024-07-24T01:58:56.159618",
     "exception": false,
     "start_time": "2024-07-24T01:58:53.731799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.4.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 1.4.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.4.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 1.4.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "comp_data_dir = Path(\"/kaggle/input/uspto-explainable-ai\")\n",
    "tfidf_dir = Path(\"/kaggle/input/uspto-ti-cpc-tfidf\")\n",
    "\n",
    "# nearest neighbors and meta\n",
    "test = pl.read_csv(comp_data_dir / \"test.csv\")\n",
    "test_meta = pl.read_parquet(\"meta_with_text.parquet\")\n",
    "\n",
    "# test index\n",
    "test_idx = whoosh_utils.load_index(\"./test_index\")\n",
    "searcher = whoosh_utils.get_searcher(test_idx)\n",
    "qp = whoosh_utils.get_query_parser()\n",
    "\n",
    "\n",
    "# for tfidf pickle\n",
    "def identity(x: Any) -> Any:\n",
    "    return x\n",
    "\n",
    "\n",
    "with open(tfidf_dir / \"tfidf.pkl\", \"rb\") as f:\n",
    "    ti_tfidf = pickle.load(f)\n",
    "with open(tfidf_dir / \"cpc_cv_tfidf.pkl\", \"rb\") as f:\n",
    "    cpc_cv_tfidf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "126a645e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T01:58:56.171997Z",
     "iopub.status.busy": "2024-07-24T01:58:56.171686Z",
     "iopub.status.idle": "2024-07-24T01:59:08.199161Z",
     "shell.execute_reply": "2024-07-24T01:59:08.198113Z"
    },
    "papermill": {
     "duration": 12.036435,
     "end_time": "2024-07-24T01:59:08.201640",
     "exception": false,
     "start_time": "2024-07-24T01:58:56.165205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:21,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Problem Number 0 Score: 0.9987918367346938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:12,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Problem Number 1 Score: 0.9812534726942382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:04<00:09,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Problem Number 2 Score: 0.9983751700680271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:05<00:07,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Problem Number 3 Score: 0.9796223024574935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:06<00:06,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Problem Number 4 Score: 0.9813074936000219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:07<00:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Problem Number 5 Score: 0.9925409403020394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:08<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Problem Number 6 Score: 0.9987918367346938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:09<00:02,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Problem Number 7 Score: 0.965436808364758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:11<00:01,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Problem Number 8 Score: 0.9908473661457406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Problem Number 9 Score: 0.9923800930423198\n",
      "Average Score: 0.9879347320144026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(len(test))):\n",
    "    target = test[i].to_numpy().flatten()[1:].tolist()\n",
    "    file = test[i].to_numpy().flatten().tolist()\n",
    "    meta_i = test_meta.filter(pl.col(\"publication_number\").is_in(file))\n",
    "\n",
    "    if len(meta_i) == 0:\n",
    "        # append dummy\n",
    "        results.append({\"publication_number\": test[i, \"publication_number\"], \"query\": \"ti:device\"})\n",
    "        print(\"\\t Append Dummy\", i)\n",
    "        continue\n",
    "\n",
    "    # TF-IDF matrix\n",
    "    ti_mat = ti_tfidf.transform(meta_i.get_column(\"title\").fill_null(\"\"))\n",
    "    cpc_mat = cpc_cv_tfidf.transform(meta_i.get_column(\"cpc\"))\n",
    "\n",
    "    # Important topk words\n",
    "    X_ti, idx = select_top_k_columns(ti_mat, k=80)\n",
    "    X_cpc, cpc_idx = select_top_k_columns(cpc_mat, k=80)\n",
    "\n",
    "    # Initialize State with topk words\n",
    "    # The initial query is \"word1 OR word2 OR word3 OR ...\"\"\n",
    "    topk_words = ti_tfidf.get_feature_names_out()[idx].tolist()\n",
    "    topk_cpc = cpc_cv_tfidf.get_feature_names_out()[cpc_idx]\n",
    "    #topk_words = [Word(category=\"ti\", content=x) for x in topk_words]\n",
    "    #topk_cpc = [Word(category=\"cpc\", content=x) for x in topk_cpc]\n",
    "    #words = topk_words + topk_cpc\n",
    "    #state = State(words=words)\n",
    "\n",
    "    # Determine which words to use using the annealing method\n",
    "    # 2500 * 5 / 60 / 60 = 3.47 [hour]\n",
    "    #problem = USPTOProblem(qp, searcher, target, state, steps=1000, max_time=10)\n",
    "    #solution, score = problem.anneal()\n",
    "    \n",
    "    topk_words = [f\"ti:{x}\" for x in topk_words]\n",
    "    topk_cpc = [f\"cpc:{x}\" for x in topk_cpc]\n",
    "    \n",
    "    query_score_pairs = []  \n",
    "    for query in topk_words + topk_cpc:  \n",
    "        cand = whoosh_utils.execute_query(query, qp, searcher)  \n",
    "        ap50_score = ap50(cand, target)  \n",
    "        # 将查询和分数作为一个元组添加到列表中  \n",
    "        if ap50_score>0:\n",
    "            query_score_pairs.append((query, ap50_score))\n",
    "        \n",
    "    # 根据分数（元组的第二个元素）对列表进行排序  \n",
    "    sorted_query_score_pairs = sorted(query_score_pairs, key=lambda x: x[1], reverse=True)  # reverse=True表示按降序排序  \n",
    "\n",
    "    # 如果你只需要排序后的查询列表  \n",
    "    sorted_queries = [pair[0] for pair in sorted_query_score_pairs] \n",
    "    \n",
    "    check_w = []\n",
    "    score = 0\n",
    "    for s in sorted_queries:\n",
    "        check_w.append(s)\n",
    "        query = \" OR \".join(check_w)\n",
    "        \n",
    "        cand = whoosh_utils.execute_query(query, qp, searcher)  \n",
    "        ap50_score = ap50(cand, target)   \n",
    "        \n",
    "        if whoosh_utils.count_query_tokens(query) >=50:\n",
    "            check_w.remove(s)\n",
    "            break\n",
    "            \n",
    "        if ap50_score<score:\n",
    "            check_w.remove(s)\n",
    "        else:\n",
    "            score = ap50_score\n",
    "            \n",
    "    word = check_w\n",
    "    k = 0\n",
    "    #j = 0\n",
    "    for j in range(len(word)):\n",
    "        word_now = word.copy()\n",
    "        word_now.pop(k)\n",
    "        query = \" OR \".join(word_now)\n",
    "        cand = whoosh_utils.execute_query(query, qp, searcher)\n",
    "        ap50_score = ap50(cand, target)\n",
    "\n",
    "        if ap50_score>=score:\n",
    "            score = ap50_score\n",
    "            word = word_now.copy()\n",
    "        else:\n",
    "            k+=1\n",
    "        #j+=1  \n",
    "        \n",
    "    \n",
    "    print(f\"\\t Problem Number {i} Score:\", score)\n",
    "    scores.append(score)\n",
    "\n",
    "    # save publication number and query\n",
    "    results.append(\n",
    "        {\"publication_number\": test[i, \"publication_number\"], \"query\": \" OR \".join(word)}\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Average Score:\", sum(scores) / len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063c15c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T01:59:08.218019Z",
     "iopub.status.busy": "2024-07-24T01:59:08.217614Z",
     "iopub.status.idle": "2024-07-24T01:59:09.226716Z",
     "shell.execute_reply": "2024-07-24T01:59:09.225629Z"
    },
    "papermill": {
     "duration": 1.019908,
     "end_time": "2024-07-24T01:59:09.228986",
     "exception": false,
     "start_time": "2024-07-24T01:59:08.209078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove unwanted files and directories that may cause submission errors\n",
    "!rm -rf /kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "634499ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T01:59:09.245621Z",
     "iopub.status.busy": "2024-07-24T01:59:09.244737Z",
     "iopub.status.idle": "2024-07-24T01:59:09.268409Z",
     "shell.execute_reply": "2024-07-24T01:59:09.267526Z"
    },
    "papermill": {
     "duration": 0.035004,
     "end_time": "2024-07-24T01:59:09.271502",
     "exception": false,
     "start_time": "2024-07-24T01:59:09.236498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>publication_number</th><th>query</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;US-2017082634-…</td><td>&quot;cpc:G01N33/684…</td></tr><tr><td>&quot;US-2017180470-…</td><td>&quot;ti:method OR c…</td></tr><tr><td>&quot;US-2018029544-…</td><td>&quot;ti:solar OR ti…</td></tr><tr><td>&quot;US-2022408153-…</td><td>&quot;ti:apparatus O…</td></tr><tr><td>&quot;US-2268569-A&quot;</td><td>&quot;ti:machine OR …</td></tr><tr><td>&quot;US-3371854-A&quot;</td><td>&quot;ti:pump OR cpc…</td></tr><tr><td>&quot;US-3589189-A&quot;</td><td>&quot;ti:meter OR ti…</td></tr><tr><td>&quot;US-3881203-A&quot;</td><td>&quot;ti:holder OR t…</td></tr><tr><td>&quot;US-4845770-A&quot;</td><td>&quot;ti:reader OR t…</td></tr><tr><td>&quot;US-695233-A&quot;</td><td>&quot;cpc:C10H15/06 …</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "┌────────────────────┬───────────────────────────────────┐\n",
       "│ publication_number ┆ query                             │\n",
       "│ ---                ┆ ---                               │\n",
       "│ str                ┆ str                               │\n",
       "╞════════════════════╪═══════════════════════════════════╡\n",
       "│ US-2017082634-A1   ┆ cpc:G01N33/6848 OR ti:mass OR ti… │\n",
       "│ US-2017180470-A1   ┆ ti:method OR cpc:H04L67/42 OR cp… │\n",
       "│ US-2018029544-A1   ┆ ti:solar OR ti:module OR cpc:H01… │\n",
       "│ US-2022408153-A1   ┆ ti:apparatus OR ti:media OR cpc:… │\n",
       "│ US-2268569-A       ┆ ti:machine OR ti:material OR ti:… │\n",
       "│ US-3371854-A       ┆ ti:pump OR cpc:H01J41/16 OR cpc:… │\n",
       "│ US-3589189-A       ┆ ti:meter OR ti:gas OR cpc:G01F3/… │\n",
       "│ US-3881203-A       ┆ ti:holder OR ti:paper OR ti:clip… │\n",
       "│ US-4845770-A       ┆ ti:reader OR ti:optical OR cpc:G… │\n",
       "│ US-695233-A        ┆ cpc:C10H15/06 OR cpc:C10H5/00 OR… │\n",
       "└────────────────────┴───────────────────────────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pl.DataFrame(results)\n",
    "submission.write_csv(\"submission.csv\")\n",
    "\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8060720,
     "sourceId": 59575,
     "sourceType": "competition"
    },
    {
     "datasetId": 4892374,
     "sourceId": 8246447,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5007812,
     "sourceId": 8413600,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4517815,
     "sourceId": 8479599,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5109610,
     "sourceId": 8553271,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 174185912,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 147.985982,
   "end_time": "2024-07-24T01:59:09.797409",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-24T01:56:41.811427",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
